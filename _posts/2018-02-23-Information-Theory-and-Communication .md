---
title: Information Theory and Communication 
description: DMCs, Entropy, Conditional Entropy, Mutual information 
categories: Information Theory
---

    The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point.  
        
      <div align="right">————C. E. SHANNON</div>   
      
>  The characterization of the channel capacity (the logarithm of the number of distinguishable signals) as the maximum mutual information is the central and most famous success of information theory.   
  
### **Discrete Memoryless Channels**    
The heart of the communication problem is **discrete** in nature: the transmitter sends one out of a finite number of codewords and the receiver would like to figure out which codeword is transmitted.   


### **Supplementary**  
##### **Capacity of Binary Erasure Channel**  


    
Reference:  
1. Thomas M. Cover, Joy A. Thomas. (2006). *Elements of Information Theory*. John Wiley & Sons. 
